{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "base_df = pd.read_csv(\"/home/samir/Desktop/rudraAnalytics/sub_projects/churn/data.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = base_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import screen_data\n",
    "# screen_data(df=df, skip=['customerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(df, encode_set=[], dont_encode=[]):\n",
    "    encoded_df = df.copy()\n",
    "    for column in encode_set:\n",
    "        if column in dont_encode:\n",
    "            continue\n",
    "        # print(len(df[column].unique()))\n",
    "        if df[column].dtype == 'object':\n",
    "            if len(df[column].unique()) == 2:\n",
    "                # Binary encoding (0 and 1)\n",
    "                encoded_df[column] = pd.get_dummies(df[column], drop_first=True)\n",
    "            else:\n",
    "                # One-hot encoding and using 0 and 1 instead of True and False\n",
    "                one_hot_encoded = pd.get_dummies(df[column], prefix=column, drop_first=False)\n",
    "                one_hot_encoded.columns = [f\"{column}{i+1}\" for i in range(one_hot_encoded.shape[1])]\n",
    "                encoded_df = pd.concat([encoded_df, one_hot_encoded], axis=1)\n",
    "                encoded_df.drop(column, axis=1, inplace=True)\n",
    "                # print(encoded_df)\n",
    "\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'customerID',\n",
    "    'gender',\n",
    "    'SeniorCitizen',\n",
    "    'Partner',\n",
    "    'Dependents',\n",
    "    'tenure',\n",
    "    'PhoneService',\n",
    "    'MultipleLines',\n",
    "    'InternetService',\n",
    "    'OnlineSecurity',\n",
    "    'OnlineBackup',\n",
    "    'DeviceProtection',\n",
    "    'TechSupport',\n",
    "    'StreamingTV',\n",
    "    'StreamingMovies',\n",
    "    'Contract',\n",
    "    'PaperlessBilling',\n",
    "    'PaymentMethod',\n",
    "    'MonthlyCharges',\n",
    "    'TotalCharges',\n",
    "    'Churn'\n",
    "]\n",
    "dont_label = ['customerID', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "encoded_df = one_hot_encode(df.drop('customerID', axis=1), features, dont_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.7306 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7304 - val_loss: nan - val_accuracy: 0.7507\n",
      "45/45 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.7353\n",
      "Test Accuracy: 73.53%\n"
     ]
    }
   ],
   "source": [
    "X = encoded_df.drop('Churn', axis=1)\n",
    "y = encoded_df['Churn']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (optional, but often beneficial for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.evaluate(X_test_scaled, y_test)[1]\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ACCURACY: 73.53%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
