{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7455 - val_loss: 0.4192 - val_accuracy: 0.8098\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7950 - val_loss: 0.4112 - val_accuracy: 0.8048\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7991 - val_loss: 0.4087 - val_accuracy: 0.8091\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8024 - val_loss: 0.4096 - val_accuracy: 0.8105\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8030 - val_loss: 0.4076 - val_accuracy: 0.8126\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8039 - val_loss: 0.4062 - val_accuracy: 0.8098\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8085 - val_loss: 0.4082 - val_accuracy: 0.8091\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8062 - val_loss: 0.4078 - val_accuracy: 0.8077\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8074 - val_loss: 0.4080 - val_accuracy: 0.8148\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.4059 - val_accuracy: 0.8197\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8062 - val_loss: 0.4081 - val_accuracy: 0.8105\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8111 - val_loss: 0.4084 - val_accuracy: 0.8119\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8149 - val_loss: 0.4135 - val_accuracy: 0.8006\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8076 - val_loss: 0.4077 - val_accuracy: 0.8162\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8110 - val_loss: 0.4080 - val_accuracy: 0.8105\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8115 - val_loss: 0.4055 - val_accuracy: 0.8141\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8122 - val_loss: 0.4082 - val_accuracy: 0.8070\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8124 - val_loss: 0.4081 - val_accuracy: 0.8126\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8149 - val_loss: 0.4080 - val_accuracy: 0.8141\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8138 - val_loss: 0.4106 - val_accuracy: 0.8126\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "Deep Learning Test Accuracy: 81.26%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_df = pd.read_csv(\"/home/samir/Desktop/rudraAnalytics/sub_projects/churn/data/data.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "df = base_df.copy()\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype(str)\n",
    "\n",
    "\n",
    "def one_hot_encode(df, encode_set=[], dont_encode=[]):\n",
    "    encoded_df = df.copy()\n",
    "    for column in encode_set:\n",
    "        if column in dont_encode:\n",
    "            continue\n",
    "        # print(len(df[column].unique()))\n",
    "        if df[column].dtype == 'object':\n",
    "            if len(df[column].unique()) == 2:\n",
    "                # Binary encoding (0 and 1)\n",
    "                encoded_df[column] = pd.get_dummies(df[column], drop_first=True)\n",
    "            else:\n",
    "                # One-hot encoding and using 0 and 1 instead of True and False\n",
    "                one_hot_encoded = pd.get_dummies(df[column], prefix=column, drop_first=False)\n",
    "                one_hot_encoded.columns = [f\"{column}{i+1}\" for i in range(one_hot_encoded.shape[1])]\n",
    "                encoded_df = pd.concat([encoded_df, one_hot_encoded], axis=1)\n",
    "                encoded_df.drop(column, axis=1, inplace=True)\n",
    "                # print(encoded_df)\n",
    "\n",
    "    return encoded_df\n",
    "\n",
    "features = [\n",
    "    'customerID',\n",
    "    'gender',\n",
    "    'SeniorCitizen',\n",
    "    'Partner',\n",
    "    'Dependents',\n",
    "    'tenure',\n",
    "    'PhoneService',\n",
    "    'MultipleLines',\n",
    "    'InternetService',\n",
    "    'OnlineSecurity',\n",
    "    'OnlineBackup',\n",
    "    'DeviceProtection',\n",
    "    'TechSupport',\n",
    "    'StreamingTV',\n",
    "    'StreamingMovies',\n",
    "    'Contract',\n",
    "    'PaperlessBilling',\n",
    "    'PaymentMethod',\n",
    "    'MonthlyCharges',\n",
    "    'TotalCharges',\n",
    "    'Churn'\n",
    "]\n",
    "dont_label = ['customerID', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "encoded_df = one_hot_encode(df.drop('customerID', axis=1), features, dont_label)\n",
    "encoded_df['TotalCharges'].fillna(encoded_df['TotalCharges'].mean(), inplace=True)\n",
    "\n",
    "X = encoded_df.drop('Churn', axis=1)\n",
    "y = encoded_df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_dl = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dl = accuracy_score(y_test, y_pred_dl)\n",
    "print(f\"Deep Learning Test Accuracy: {accuracy_dl * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Test Accuracy: 81.48%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
